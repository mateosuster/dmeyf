#Arbol elemental con libreria  rpart
require("data.table")
require("rpart")
#Aqui se debe poner la carpeta de la computadora local
setwd( "C:/Archivos/maestria_cs_datos/Materias/DM_EyF/dmeyf/")
library(readODS)
library(janitor)
dic_list = read.ods("dic/DiccionarioDatos.ods")
dic_list
dic = as.data.frame(dic_list[1]) %>%  row_to_names(row_number = 1)
dic
#cargo los datos de 202009 que es donde voy a ENTRENAR el modelo
dtrain  <- fread(  "../datasetsOri/paquete_premium_202009.csv")
#genero el modelo
modelo  <- rpart("clase_ternaria ~ .",
data = dtrain,
xval=5,
cp=        -0.34,
minsplit=  80,
minbucket=  152,
maxdepth=   8 )
rm( list=ls() )  #Borro todos los objetos
gc()   #Garbage Collection
require("data.table")
require("rpart")
#Aqui se debe poner la carpeta de la computadora local
setwd("C:/Archivos/maestria_cs_datos/Materias/DM_EyF/dmeyf/")  #Establezco el Working Directory
#cargo los datos
dataset  <- fread("../datasetsOri/paquete_premium_202009.csv")
ksemilla  <- 995641  #Cambiar por la primer semilla de cada uno !
#divido en training/testing
set.seed( ksemilla )
runif( nrow(dataset) )
# que hace runif?
runif(10)
runif(10) < 0.7
as.numeric(runif(10) < 0.7)
sum(as.numeric(runif(100) < 0.7) )
sum(as.numeric(runif(10) < 0.7) )
as.numeric(runif(10) < 0.7)
sum(as.numeric(runif(10) < 0.7))
sum(as.numeric(runif(10) < 0.7))
sum(as.numeric(runif(10) < 0.7))
sum(as.numeric(runif(10) < 0.7))
as.numeric(runif(10) < 0.7)
fold  <- ifelse( runif( nrow(dataset) ) <  0.7, 1, 2 )
#genero el modelo
modelo  <- rpart("clase_ternaria ~ .",
data= dataset[ fold==1], #1 es training
xval= 0,
cp= -1,
maxdepth= 6 )
rm( list=ls() )
gc(verbose = FALSE)
library( "data.table")
library("ggplot2")
carpeta_datasetsOri <-  "../../../datasetsOri/"
septiembre <- "paquete_premium_202009.csv"
ds <- fread(paste0(carpeta_datasetsOri, septiembre,collapse = ""), header=TRUE, showProgress = FALSE)
library(rpart)
arbol  <- rpart("clase_ternaria ~ .",
data = ds,
xval=0,
cp=0,
minsplit=  80,
minbucket=  1,
maxdepth=   5 )
arbol
library( "rpart.plot" )
prp( arbol, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0 )
rm( list=ls() )  #Borro todos los objetos
gc()   #Garbage Collection
require("data.table")
require("rpart")
# library(rpart)
library(rpart.plot)
#------------------------------------------------------------------------------
particionar  <- function( data,  division, agrupa="",  campo="fold", start=1, seed=NA )
{
if( !is.na(seed) )   set.seed( seed )
bloque  <- unlist( mapply(  function(x,y) { rep( y, x )} ,   division,  seq( from=start, length.out=length(division) )  ) )
data[ ,  (campo) :=  sample( rep( bloque, ceiling(.N/length(bloque))) )[1:.N],
by= agrupa ]
}
#------------------------------------------------------------------------------
#Aqui se debe poner la carpeta de la computadora local
setwd("C:/Archivos/maestria_cs_datos/Materias/DM_EyF/dmeyf/")  #Establezco el Working Directory
#cargo los datos
dataset  <- fread("../datasetsOri/paquete_premium_202009.csv")
particionar( dataset, division=c(70,30), agrupa="clase_ternaria", seed= 995641 )  #Cambiar por la primer semilla de cada uno !
dataset
#genero el modelo
modelo  <- rpart("clase_ternaria ~ .",
data= dataset[ fold==1],
xval= 0,
cp= -1,
maxdepth= 6 )
prediccion  <- predict( modelo, dataset[ fold==2] , type= "prob") #aplico el modelo
dataset[  , ganancia :=  ifelse( clase_ternaria=="BAJA+2", 48750, -1250 ) ]
prop.table(table(dataset$fold))
prop.table(table(dataset$fold, dataset$clase_ternaria))
prop.table(table(dataset$fold, dataset$clase_ternaria), margin = 2)
prediccion
dataset
dataset[  , ganancia :=  ifelse( clase_ternaria=="BAJA+2", 48750, -1250 ) ]
View(dataset)
dataset$prop_baja2
dataset[ fold==2 , prob_baja2 := prediccion[, "BAJA+2"] ]
dataset$prop_baja2
ganancia_test  <- dataset[ fold==2 & prob_baja2 > 0.025, sum(ganancia) ]
ganancia_test
ganancia_test_normalizada  <-  ganancia_test / 0.3
ganancia_test_normalizada
prediccion[, "BAJA+2"]
head(prediccion)
modelo
modelo$frame
dataset[ fold==2 , prob_baja2 := prediccion[, "BAJA+2"] ]
dataset[prop_baja2]
dataset[,prop_baja2]
dataset[,.prop_baja2]
dataset[ fold==2 & prob_baja2 > 0.025,]
dataset[ fold==2 & prob_baja2 > 0.025, prob_baja2]
dataset[ fold==2 , prob_baja2]
dataset[  , prob_baja2]
dataset[  , .(fold ,prob_baja2)]
x = dataset[  , .(fold ,prob_baja2)]
View(x)
dataset[  , .(prob_baja2)]
prediccion[, "BAJA+2"]
head(prediccion[, "BAJA+2"])
dataset[ fold==2 , prob_baja2]
dataset[  , .(prob_baja2)]
head(prediccion[, "BAJA+2"])
dataset[  , .(prob_baja2)]
dataset[ fold==2 , prob_baja2 := prediccion[, "BAJA+2"] ]
dataset[ fold==2 , prob_baja2]
# revision de probabilidades del fold 2
dataset[  , .(fold, prob_baja2)]
head(prediccion[, "BAJA+2"])
ganancia_test  <- dataset[ fold==2 & prob_baja2 > 0.025, sum(ganancia) ]
ganancia_test_normalizada  <-  ganancia_test / 0.3
ganancia_test_normalizada
length(c(70,30))
mapply(  function(x,y) { rep( y, x )} ,
c(70,30),
seq( from=1, length.out=length(c(70,30)) )  )
unlist( mapply(  function(x,y) { rep( y, x )} ,
c(70,30),
seq( from=1, length.out=length(c(70,30)) )  ) )
rm(list=ls())   #remove all objects
gc()            #garbage collection
require("data.table")
require("parallel")
require("rpart")
setwd( "C:/Archivos/maestria_cs_datos/Materias/DM_EyF/dmeyf/" )
setwd( "~/buckets/b1/crudoB/" )
ksemillas  <- c(995641, 433747, 536651, 388519, 269897) #reemplazar por las propias semillas
ksemilla_extra  <- 102191  #reemplazar por una elegida en el momento
particionar  <- function( data,  division, agrupa="",  campo="fold", start=1, seed=NA )
{
if( !is.na(seed) )   set.seed( seed )
bloque  <- unlist( mapply(  function(x,y) { rep( y, x )} ,   division,  seq( from=start, length.out=length(division) )  ) )
data[ ,  (campo) :=  sample( rep( bloque, ceiling(.N/length(bloque))) )[1:.N],
by= agrupa ]
}
ArbolSimple  <- function( fold_test, data, param )
{
#genero el modelo
modelo  <- rpart("clase_ternaria ~ .",
data= data[ fold != fold_test, ], #training  fold==1
xval= 0,
control= param )
#aplico el modelo a los datos de testing, fold==2
prediccion  <- predict( modelo, data[ fold==fold_test, ], type = "prob")
prob_baja2  <- prediccion[, "BAJA+2"]
ganancia_testing  <- sum(  data[ fold==fold_test ][ prob_baja2 >0.025,  ifelse( clase_ternaria=="BAJA+2", 48750, -1250 ) ] )
return( ganancia_testing )
}
ArbolEstimarGanancia  <- function( semilla, data, param )
{
pct_test  <- 30/(30+70)
particionar( data, division=c(70,30), agrupa="clase_ternaria", seed=semilla )
ganancia_testing  <- ArbolSimple( 2, data, param )
ganancia_testing_normalizada  <- ganancia_testing / pct_test   #normalizo la ganancia
return( ganancia_testing_normalizada )
}
ArbolesMontecarlo  <- function( data, param, semillas )
{
ganancias  <- mcmapply( ArbolEstimarGanancia,
semillas,
MoreArgs= list( data, param),
SIMPLIFY= FALSE,
mc.cores= 1 )  #se puede subir a 5 si posee Linux o Mac OS
#devuelvo la primer ganancia y el promedio
return( mean( unlist( ganancias ))  )
}
#cargo los datos donde voy a ENTRENAR el modelo
dataset  <- fread("../datasetsOri/paquete_premium_202009.csv")
#inicializo la tabla donde voy a dejar los resultados
tb_resultados  <- data.table( maxdepth=integer(), ganancia1=numeric(), ganancia5=numeric()  )
tb_resultados
for(  vmaxdepth in  c(4,5,6,7,8,9,10,11) )
#cargo los datos donde voy a ENTRENAR el modelo
dataset  <- fread("../datasetsOri/paquete_premium_202009.csv")
for(  vmaxdepth in  c(4,5,6,7,8,9,10,11) )
{
param_basicos  <- list( "cp"=-1, "minsplit"=20, "minbucket"=7,  "maxdepth"= vmaxdepth )
gan1  <- ArbolesMontecarlo( dataset, param_basicos, ksemilla_extra )
gan5  <- ArbolesMontecarlo( dataset, param_basicos, ksemillas )
tb_resultados  <- rbind( tb_resultados, list( vmaxdepth, gan1, gan5 ) )
}
tb_resultados
#limpio la memoria
rm(list=ls())   #remove all objects
gc()            #garbage collection
require("data.table")
require("parallel")
require("rpart")
setwd( "C:/Archivos/maestria_cs_datos/Materias/DM_EyF/dmeyf/" )
ksemillas  <- c(995641, 433747, 536651, 388519, 269897) #reemplazar por las propias semillas
#------------------------------------------------------------------------------
particionar  <- function( data, division, agrupa="", campo="fold", start=1, seed=NA )
{
if( !is.na(seed) )   set.seed( seed )
bloque  <- unlist( mapply(  function(x,y) { rep( y, x )} ,   division,  seq( from=start, length.out=length(division) )  ) )
data[ , (campo) :=  sample( rep( bloque, ceiling(.N/length(bloque))) )[1:.N],
by= agrupa ]
}
#------------------------------------------------------------------------------
ArbolSimple  <- function( fold_test, data, param )
{
#genero el modelo
modelo  <- rpart("clase_ternaria ~ .",
data= data[ fold != fold_test, ], #training  fold==1
xval= 0,
control= param )
#aplico el modelo a los datos de testing, fold==2
prediccion  <- predict( modelo, data[ fold==fold_test, ], type = "prob")
prob_baja2  <- prediccion[, "BAJA+2"]
ganancia_testing  <- sum(  data[ fold==fold_test ][ prob_baja2 >0.025,  ifelse( clase_ternaria=="BAJA+2", 48750, -1250 ) ] )
return( ganancia_testing )
}
#------------------------------------------------------------------------------
ArbolesCrossValidation  <- function( data, param, qfolds, semilla )
{
divi  <- rep( 1, qfolds )
particionar( data, divi, agrupa="clase_ternaria", seed=semilla )
ganancias  <- mcmapply( ArbolSimple,
seq(qfolds), # 1 2 3 4 5
MoreArgs= list( data, param),
SIMPLIFY= FALSE,
mc.cores= 1 )   #se puede subir a 5 si posee Linux o Mac OS
#devuelvo la primer ganancia y el promedio
return( mean( unlist( ganancias )) *  qfolds )   #aqui normalizo
}
#------------------------------------------------------------------------------
#cargo los datos donde voy a ENTRENAR el modelo
dataset  <- fread("../datasetsOri/paquete_premium_202009.csv")
#inicializo la tabla donde voy a dejar los resultados
tb_resultados  <- data.table( maxdepth=integer(), ganancia=numeric() )
for(  vmaxdepth in  c(4,5,6,7,8,9,10,11) )
{
param_basicos  <- list( "cp"=-1, "maxdepth"= vmaxdepth )
gan  <- ArbolesCrossValidation( dataset,
param_basicos,
qfolds= 5, # 5-fold cross validation
semilla= ksemillas[1] )  #uso solo la primer semilla para particionar el dataset
tb_resultados  <- rbind( tb_resultados, list( vmaxdepth, gan ) )
}
tb_resultados
tb_resultados
